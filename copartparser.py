import asyncio
import csv
import json
import os
import re
from datetime import datetime, timezone, timedelta
from pathlib import Path
from typing import Any, Dict, List, Optional

import aiosqlite
import httpx
from dotenv import load_dotenv
from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeoutError
from io import BytesIO
from urllib.parse import urlparse
import mimetypes
from app.services.store.s3contabo import s3_service
from app.core.config.config import settings

load_dotenv()

# =======================
# –ö–æ–Ω—Ñ–∏–≥
# =======================

COPART_USER = os.getenv("COPART_USER", "")
COPART_PASS = os.getenv("COPART_PASS", "")
HEADLESS = os.getenv("HEADLESS", "1") == "0"

LOCAL_BATCH_URL = os.getenv("LOCAL_BATCH_URL", "http://37.60.253.236:89/lot/lots/batch")
LOCAL_AUTH = os.getenv("LOCAL_AUTH", "8fd3b8c4b91e47f5a6e2d7c9f1a4b3d2")  # secret_key –∏–∑ .env

MAX_BATCH_SIZE = int(os.getenv("MAX_BATCH_SIZE", "100"))

# URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø–æ–∏—Å–∫–∞ —Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏
SEARCH_RESULTS_URL = (
    "https://www.copart.com/lotSearchResults?free=false&searchCriteria="
    "%7B%22query%22:%5B%22*%22%5D,%22filter%22:%7B%22ODM%22:%5B%22odometer_reading_received:%5B0%20TO%209999999%5D%22%5D,"
    "%22YEAR%22:%5B%22lot_year:%5B2015%20TO%202026%5D%22%5D,%22MISC%22:%5B%22%23VehicleTypeCode:VEHTYPE_V%22%5D%7D,"
    "%22searchName%22:%22%22,%22watchListOnly%22:false,%22freeFormSearch%22:false%7D%20"
    "&displayStr=AUTOMOBILE,%5B0%20TO%209999999%5D,%5B2015%20TO%202026%5D&from=%2FvehicleFinder"
    "&fromSource=widget&qId=af2f7b1c-fd0a-11e9-a583-48df3771ed50-1763666292713"
)
IMAGE_CONCURRENCY = int(os.getenv("IMAGE_CONCURRENCY", "5")) 
# START_LINK_INDEX = int(os.getenv("START_LINK_INDEX", "0")) == 539
START_LINK_INDEX = 539
# =======================
# –£—Ç–∏–ª–∏—Ç—ã
# =======================
def now_iso_utc() -> str:
    return datetime.now(timezone.utc).isoformat()
# =======================
# NHTSA VIN decode helpers (Body Class)
# =======================

BODY_CLASS_MAP: dict[str, str] = {
    "sedan/saloon": "Sedan",
    "sport utility vehicle (suv)": "SUV",
    "sport utility vehicle": "SUV",
    "pickup": "Pickup",
    "coupe": "Coupe",
    "hatchback": "Hatchback",
    "wagon": "Wagon",
    "minivan": "Minivan",
    "convertible/cabriolet": "Convertible",
}


def normalize_body_class(raw: str | None) -> Optional[str]:
    if not raw:
        return None
    key = raw.strip().lower()
    return BODY_CLASS_MAP.get(key, raw.strip())


async def fetch_body_class_from_nhtsa(vin: str, client: httpx.AsyncClient) -> Optional[str]:
    """
    –î–æ—Å—Ç–∞—ë—Ç Body Class –∏–∑ NHTSA DecodeVinExtended –ø–æ VIN.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π Body Class –∏–ª–∏ None.
    """
    vin = (vin or "").strip().upper()
    if len(vin) != 17:
        return None

    url = f"https://vpic.nhtsa.dot.gov/api/vehicles/DecodeVinExtended/{vin}?format=json"
    try:
        resp = await client.get(url, timeout=15)
        resp.raise_for_status()
    except Exception as e:
        print(f"‚ö†Ô∏è NHTSA error for VIN {vin}: {e}")
        return None

    try:
        data = resp.json()
    except Exception as e:
        print(f"‚ö†Ô∏è NHTSA JSON parse error for VIN {vin}: {e}")
        return None

    results = data.get("Results") or []
    body_val: Optional[str] = None
    for row in results:
        if row.get("Variable") == "Body Class":
            value = row.get("Value")
            if value:
                body_val = value
                break

    return normalize_body_class(body_val)


# =======================
# SessionStore (SQLite)
# =======================

class SessionStore:
    """
    –ü—Ä–æ—Å—Ç–µ–π—à–µ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ storage_state –≤ SQLite.
    –ö–ª—é—á–æ–º –∏—Å–ø–æ–ª—å–∑—É–µ–º username.
    """
    def __init__(self, db_path: str = "sessions.db"):
        self.db_path = db_path

    async def init(self):
        async with aiosqlite.connect(self.db_path) as db:
            await db.execute(
                """
                CREATE TABLE IF NOT EXISTS bot_sessions (
                    username TEXT PRIMARY KEY,
                    storage_state_json TEXT NOT NULL,
                    updated_at TEXT NOT NULL
                )
                """
            )
            await db.commit()

    async def get_storage_state(self, username: str) -> Optional[Dict[str, Any]]:
        async with aiosqlite.connect(self.db_path) as db:
            async with db.execute(
                "SELECT storage_state_json FROM bot_sessions WHERE username = ?",
                (username,),
            ) as cur:
                row = await cur.fetchone()
                if not row:
                    return None
                try:
                    return json.loads(row[0])
                except Exception:
                    return None

    async def save_storage_state(self, username: str, storage_state: Dict[str, Any]):
        payload = json.dumps(storage_state, ensure_ascii=False)
        now = now_iso_utc()
        async with aiosqlite.connect(self.db_path) as db:
            await db.execute(
                """
                INSERT INTO bot_sessions(username, storage_state_json, updated_at)
                VALUES (?, ?, ?)
                ON CONFLICT(username) DO UPDATE SET
                  storage_state_json=excluded.storage_state_json,
                  updated_at=excluded.updated_at
                """,
                (username, payload, now),
            )
            await db.commit()


# =======================
# CopartBot
# =======================

class CopartBot:
    def __init__(self, username: str, password: str, headless: bool = True):
        self.username = username
        self.password = password
        self.headless = headless

        self._pw = None
        self.browser = None
        self.context = None
        self.page = None

    async def start(self, storage_state=None):
        self._pw = await async_playwright().start()

        expose_cdp = os.getenv("EXPOSE_CDP", "1") == "1"
        cdp_port = int(os.getenv("CDP_PORT", "9222"))

        launch_args = [
            "--no-sandbox",
            "--disable-dev-shm-usage",
        ]
        if expose_cdp:
            launch_args += [
                f"--remote-debugging-port={cdp_port}",
                "--remote-debugging-address=0.0.0.0",
            ]

        self.browser = await self._pw.chromium.launch(
            headless=self.headless,
            args=launch_args,
        )
        self.context = await self.browser.new_context(
            storage_state=storage_state,
        )
        self.page = await self.context.new_page()
        return self

    async def close(self):
        try:
            if self.context:
                await self.context.close()
            if self.browser:
                await self.browser.close()
        finally:
            if self._pw:
                await self._pw.stop()

    async def storage_state(self) -> Dict[str, Any]:
        return await self.context.storage_state()

    async def _maybe_accept_cookies(self):
        try:
            await self.page.locator("text=Accept").first.click(timeout=2000)
        except Exception:
            pass

    async def _scroll_to_bottom(self, step: int = 1500, max_iters: int = 20):
        prev_height = await self.page.evaluate("document.body.scrollHeight")
        iters = 0
        while iters < max_iters:
            iters += 1
            await self.page.mouse.wheel(0, step)
            await self.page.wait_for_timeout(250)
            cur_height = await self.page.evaluate("document.body.scrollHeight")
            if cur_height <= prev_height:
                await self.page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
                await self.page.wait_for_timeout(300)
                cur_height = await self.page.evaluate("document.body.scrollHeight")
                if cur_height <= prev_height:
                    break
            prev_height = cur_height

    async def _gather_all_copart_thumbnails(self, max_clicks: int = 30) -> list[str]:
        """
        –°–æ–±–∏—Ä–∞–µ—Ç –í–°–ï –∫–∞—Ä—Ç–∏–Ω–∫–∏ Copart –¥–ª—è –ª–æ—Ç–∞, –ª–∏—Å—Ç–∞—è —Å–ª–∞–π–¥–µ—Ä —Å—Ç—Ä–µ–ª–∫–æ–π
        'thumbnail-next-image-icon' –∏ –ø—Ä–æ—Ö–æ–¥—è—Å—å –ø–æ –≤—Å–µ–º <img>.

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ thumbnail-URL'–æ–≤ –≤–∏–¥–∞ *_thb.jpg (—É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö).
        """

        async def grab_all_copart_imgs() -> list[str]:
            """
            –ë–µ—Ä—ë–º –≤—Å–µ <img>, —É –∫–æ—Ç–æ—Ä—ã—Ö src —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ copart ids-c-prod-lpp.
            """
            try:
                urls = await self.page.eval_on_selector_all(
                    "img",
                    """
                    els => els
                      .map(e => (e.getAttribute('src') || '').trim())
                      .filter(u => u.includes('cs.copart.com')
                                   && u.includes('ids-c-prod-lpp'))
                    """
                )
                return [u for u in urls if u]
            except Exception:
                return []

        # –°–æ–±—Ä–∞–ª–∏ —Å—Ç–∞—Ä—Ç–æ–≤–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        seen_raw: set[str] = set(await grab_all_copart_imgs())
        print(f"  üñºÔ∏è –°—Ç–∞—Ä—Ç–æ–≤—ã—Ö Copart-URL (–≤—Å–µ img): {len(seen_raw)}")

        # –õ–∏—Å—Ç–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Å–ª–∞–π–¥–µ—Ä
        no_new_streak = 0

        for i in range(max_clicks):
            btn = self.page.locator(
                "span.lot-details-sprite.thumbnail-next-image-icon"
            ).first

            try:
                visible = await btn.is_visible()
            except Exception:
                visible = False

            if not visible:
                print(f"  üîö –ö–Ω–æ–ø–∫–∞ next-image –Ω–µ –≤–∏–¥–Ω–∞, —Å—Ç–æ–ø (–∫–ª–∏–∫ {i+1}/{max_clicks})")
                break

            print(f"  üîÅ –ö–ª–∏–∫–∞—é next-image (–∫–ª–∏–∫ {i+1}/{max_clicks})...")
            try:
                await btn.click()
            except Exception as e:
                print(f"  ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∫–ª–∏–∫–Ω—É—Ç—å –ø–æ next-image: {e}")
                break

            await self.page.wait_for_timeout(600)

            current = set(await grab_all_copart_imgs())
            new_urls = current - seen_raw
            print(f"  ‚ûï –ù–æ–≤—ã—Ö Copart-URL –ø–æ—Å–ª–µ –∫–ª–∏–∫–∞: {len(new_urls)}")

            if not new_urls:
                no_new_streak += 1
                if no_new_streak >= 3:
                    print("  üîö –£–∂–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–ª–∏–∫–æ–≤ –Ω–µ—Ç –Ω–æ–≤—ã—Ö –∫–∞—Ä—Ç–∏–Ω–æ–∫, –≤—ã—Ö–æ–∂—É.")
                    break
            else:
                no_new_streak = 0
                seen_raw |= new_urls

        print(f"  ‚úÖ –í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö Copart-URL (—Å—ã—Ä—ã—Ö): {len(seen_raw)}")

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç *_thb.*
        thumbs: set[str] = set()

        for url in seen_raw:
            u = url.strip()
            if not u:
                continue

            # –ï—Å–ª–∏ —ç—Ç–æ —É–∂–µ thumbnail
            if "_thb" in u:
                thumbs.add(u)
                continue

            # –ï—Å–ª–∏ —ç—Ç–æ *_ful –∏–ª–∏ *_hrs ‚Äî –ø—Ä–∏–≤–æ–¥–∏–º –∫ *_thb
            if any(s in u for s in ("_ful", "_hrs")):
                base, ext = os.path.splitext(u)
                base = base.replace("_ful", "").replace("_hrs", "")
                thumbs.add(f"{base}_thb{ext}")
                continue

            # –ï—Å–ª–∏ –≤–æ–æ–±—â–µ –±–µ–∑ —Å—É—Ñ—Ñ–∏–∫—Å–∞ ‚Äî –¥–æ–±–∞–≤–∏–º _thb –∫–∞–∫ fallback
            base, ext = os.path.splitext(u)
            thumbs.add(f"{base}_thb{ext or '.jpg'}")

        thumbs_list = list(dict.fromkeys(sorted(thumbs)))
        print(f"  üéØ –ò—Ç–æ–≥–æ thumbnail-URL (*_thb): {len(thumbs_list)}")
        return thumbs_list



    # ---------- auth / health ----------

    async def login_member(self) -> bool:
        await self.page.goto("https://www.copart.com", wait_until="domcontentloaded")
        await self._maybe_accept_cookies()

        await self.page.click("button[data-uname='homePageSignIn']")
        await self.page.wait_for_selector(
            "a[data-uname='homePageMemberSignIn']",
            timeout=8000,
        )
        await self.page.click("a[data-uname='homePageMemberSignIn']")

        await self.page.wait_for_selector("input#username")
        await self.page.fill("input#username", self.username)
        await self.page.fill("input#password", self.password)

        await self.page.click("button[data-uname='loginSigninmemberbutton']")

        try:
            await self.page.wait_for_url("**/dashboard*", timeout=25000)
            await self.page.wait_for_selector("text=Hi,", timeout=20000)
            greet = await self.page.locator("text=Hi,").first.text_content()
            print(f"‚úÖ –í–æ—à—ë–ª: {(greet or '').strip()}")
            return True
        except PlaywrightTimeoutError as e:
            print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å –≤—Ö–æ–¥: {e}")
            return False

    async def health_check(self) -> bool:
        try:
            await self.page.goto("https://www.copart.com/dashboard", wait_until="domcontentloaded")
            await self._maybe_accept_cookies()
            await self.page.wait_for_selector("text=Hi,", timeout=8000)
            return True
        except Exception:
            return False

    async def ensure_session(self, store: SessionStore) -> bool:
        ok = await self.health_check()
        if ok:
            return True

        print("üîê –°–µ—Å—Å–∏—è –Ω–µ–≤–∞–ª–∏–¥–Ω–∞ ‚Äî –ª–æ–≥–∏–Ω—é—Å—å –∑–∞–Ω–æ–≤–æ‚Ä¶")
        ok = await self.login_member()
        if not ok:
            return False

        state = await self.storage_state()
        await store.save_storage_state(self.username, state)
        return True

    # ---------- –ø–µ—Ä–µ—Ö–æ–¥ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –ø–æ–∏—Å–∫–∞ ----------

    async def goto_search_results(self):
        print("üåê –û—Ç–∫—Ä—ã–≤–∞—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –ø–æ–∏—Å–∫–∞ —Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏...")
        await self.page.goto(SEARCH_RESULTS_URL, wait_until="domcontentloaded")
        await self._maybe_accept_cookies()
        await self.page.wait_for_load_state("networkidle")
        await self.page.wait_for_timeout(2000)

    # ---------- —ç–∫—Å–ø–æ—Ä—Ç CSV ----------

    async def export_csv_once(self) -> Optional[str]:
        """
        –ù–∞–∂–∏–º–∞–µ—Ç 'New list view', –∑–∞—Ç–µ–º '–≠–∫—Å–ø–æ—Ä—Ç', –∂–¥—ë—Ç CSV.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É.
        """
        print("üì• –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ —ç–∫—Å–ø–æ—Ä—Ç—É...")

        # 1. –ü–µ—Ä–µ–π—Ç–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –ø–æ–∏—Å–∫–∞
        await self.goto_search_results()

        # 2. –ù–∞–∂–∞—Ç—å 'New list view'
        try:
            print("üîÑ –ü–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å –≤ New list view‚Ä¶")
            new_list_btn = self.page.locator("span:has-text('New list view')").first
            await new_list_btn.wait_for(state="visible", timeout=15000)
            await new_list_btn.click()
            await self.page.wait_for_timeout(1500)
        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–∂–∞—Ç—å 'New list view': {e}")

        # 3. –ù–∞–π—Ç–∏ –∫–Ω–æ–ø–∫—É –≠–∫—Å–ø–æ—Ä—Ç
        print("üì¶ –ñ–¥—É –∫–Ω–æ–ø–∫—É '–≠–∫—Å–ø–æ—Ä—Ç'...")
        export_btn = self.page.locator("button.export-csv-button").first
        await export_btn.wait_for(state="visible", timeout=25000)

        # 4. –°–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª
        async with self.page.expect_download() as download_info:
            print("üì• –ñ–º—É –∫–Ω–æ–ø–∫—É '–≠–∫—Å–ø–æ—Ä—Ç' –∏ –∂–¥—É CSV‚Ä¶")
            await export_btn.click()

        download = await download_info.value
        path = await download.path()
        filename = download.suggested_filename

        print(f"‚úÖ CSV —Å–∫–∞—á–∞–Ω: {filename} ‚Üí {path}")
        return path

    # ---------- helpers for lot ----------

    def _lot_id_from_url(self, url: str) -> Optional[str]:
        m = re.search(r"/lot/(\d+)", url)
        return m.group(1) if m else None

    async def _ensure_on_lot(self, expected_url: str, *, attempts: int = 3) -> bool:
        exp_lot = self._lot_id_from_url(expected_url)
        for i in range(1, attempts + 1):
            cur = self.page.url
            cur_lot = self._lot_id_from_url(cur)

            dom_lot = ""
            try:
                await self.page.wait_for_selector(
                    "h1.title, #LotNumber, .lot-detail-section",
                    timeout=6000,
                )
                try:
                    dom_lot = (await self.page.locator("#LotNumber").first.inner_text()).strip()
                except Exception:
                    dom_lot = ""
            except Exception:
                pass

            if cur_lot == exp_lot or (dom_lot and exp_lot and exp_lot in dom_lot):
                return True

            print(
                f"‚ö†Ô∏è –ù–µ —Ç–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –ª–æ—Ç–∞ (got URL lot={cur_lot}, "
                f"DOM lot={dom_lot or '‚Äî'}, need={exp_lot}) ‚Äî –ø–æ–ø—ã—Ç–∫–∞ {i}/{attempts}"
            )
            await self.page.goto(expected_url, wait_until="domcontentloaded")
            await self.page.wait_for_selector(
                "h1.title, #LotNumber, .lot-detail-section",
                timeout=15000,
            )
            await self._scroll_to_bottom(step=1200, max_iters=2)
        return False

    # ---------- get_lot_details ----------

    async def get_lot_details(self, lot_url: str) -> Dict[str, Any]:
        """
        –û—Ç–∫—Ä—ã–≤–∞–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—É –ª–æ—Ç–∞ –∏ –≤—ã—Ç—è–≥–∏–≤–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ –ø–æ–ª—è + —Å—Å—ã–ª–∫–∏ –Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–∏.
        """
        await self.page.goto(lot_url, wait_until="domcontentloaded")
        ok = await self._ensure_on_lot(lot_url, attempts=3)
        if not ok:
            raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π URL –ª–æ—Ç–∞")

        await self.page.wait_for_selector(
            "h1.title, #LotNumber, .lot-detail-section",
            timeout=20000
        )
        await self.page.wait_for_timeout(120)
        await self._scroll_to_bottom(step=1200, max_iters=2)

        # –î–æ–∂–¥—ë–º—Å—è –ø–æ—è–≤–ª–µ–Ω–∏—è —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ–π –∫–∞—Ä—Ç–∏–Ω–∫–∏ (—á—Ç–æ–±—ã –≥–∞–ª–µ—Ä–µ—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª–∞—Å—å)
        try:
            await self.page.wait_for_selector(
                ".p-galleria-thumbnail-items img, .p-galleria-img-thumbnail, img[src*='ids-c-prod-lpp']",
                timeout=5000,
            )
        except Exception:
            pass

        # 1) –¢—è–Ω–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –¥–µ—Ç–∞–ª–∏
        details = await self.page.evaluate(r"""
        () => {
        const txt = (sel) => {
            const el = document.querySelector(sel);
            return el ? (el.textContent || "").replace(/\s+/g, " ").trim() : "";
        };
        const byLabel = (needle) => {
            const labs = Array.from(document.querySelectorAll("label"));
            for (const l of labs) {
                const t = (l.textContent || "").replace(/\s+/g, " ").trim().toLowerCase();
                if (!t) continue;
                if (t.startsWith(needle.toLowerCase())) {
                    const parent = l.closest(".d-flex") || l.parentElement;
                    const v = parent ? parent.querySelector(".lot-details-desc") : null;
                    if (v) return (v.textContent || "").replace(/\s+/g, " ").trim();
                }
            }
            return "";
        };

        const vinEl = document.querySelector("div[masking][number]");
        const vinAttr = vinEl ? vinEl.getAttribute("number") : "";
        const vin = vinAttr || txt("span[data-uname='lotdetailVinvalue']");

        const lotFromPage = txt("#LotNumber");
        const lotFromUrl = (location.pathname.match(/\/lot\/(\d+)/) || [])[1] || "";

        const saleLocation = txt("div#sale-information-block a[data-uname='lotdetailSaleinformationlocationvalue']");
        let saleState = "";
        if (saleLocation) {
            const parts = saleLocation.split("-");
            if (parts.length > 0) {
                saleState = parts[0].trim();
            }
        }

        const timeLeft = txt("span[data-uname='lotdetailSaleinformationtimeleftvalue']");
        const currentBid = txt("span.bid-price");
        const estimatedRetail = txt("span[data-uname='lotdetailEstimatedretailvalue']");

        return {
            title: txt("h1.title"),
            lot_number: lotFromPage || lotFromUrl,
            vin,
            title_code: txt("span[data-uname='lotdetailTitledescriptionvalue']"),
            odometer: txt("span[data-uname='lotdetailOdometervalue']"),
            primary_damage: txt("span[data-uname='lotdetailPrimarydamagevalue']"),
            cylinders: txt("span[data-uname='lotdetailCylindervalue']"),
            color: txt("span[data-uname='lotdetailColorvalue']"),
            engine_type: txt("span[data-uname='lotdetailEnginetype']"),
            transmission: byLabel("transmission"),
            drive: txt("span[data-uname='DriverValue']"),
            vehicle_type: txt("span[data-uname='lotdetailvehicletype']"),
            fuel: txt("span[data-uname='lotdetailFuelvalue']"),
            keys: txt("span[data-uname='lotdetailKeyvalue']"),

            // –∫–∞—Ä—Ç–∏–Ω–∫–∏ –∑–∞–ø–æ–ª–Ω–∏–º –∏–∑ Python
            images: [],

            sale_state: saleState,
            sale_location: saleLocation,
            time_left: timeLeft,
            current_bid: currentBid,
            estimated_retail_value: estimatedRetail,
        };
        }
        """)

        # 2) –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ copart-–∫–∞—Ä—Ç–∏–Ω–∫–∏ —á–µ—Ä–µ–∑ –ª–∏—Å—Ç–∞–Ω–∏–µ —Å–ª–∞–π–¥–µ—Ä–∞
        thumbs = await self._gather_all_copart_thumbnails(max_clicks=30)
        details["images"] = thumbs

        details["lot_link"] = lot_url
        return details





# =======================
# –ß—Ç–µ–Ω–∏–µ CSV –∏ —Å—Å—ã–ª–∫–∏
# =======================

def extract_links_from_csv(csv_path: str) -> List[str]:
    """
    –°—á–∏—Ç—ã–≤–∞–µ—Ç CSV –∏ –≤—ã—Ç–∞—Å–∫–∏–≤–∞–µ—Ç —Å—Å—ã–ª–∫–∏ –Ω–∞ –ª–æ—Ç—ã.
    –ù–ï –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∏–º–µ–Ω–∏ –∫–æ–ª–æ–Ω–∫–∏: –∏—â–µ—Ç –≤–æ –≤—Å–µ—Ö –∑–Ω–∞—á–µ–Ω–∏—è—Ö –ø–æ–¥—Å—Ç—Ä–æ–∫—É 'copart.com/lot/'.
    """
    path = Path(csv_path)
    if not path.exists():
        raise FileNotFoundError(f"CSV —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {csv_path}")

    print(f"üìÑ –ß–∏—Ç–∞—é CSV: {csv_path}")
    links_set: set[str] = set()

    with path.open(newline="", encoding="utf-8-sig") as f:
        reader = csv.DictReader(f)

        print("üßæ –ö–æ–ª–æ–Ω–∫–∏ CSV:", reader.fieldnames)

        for row in reader:
            if not row:
                continue
            for value in row.values():
                if not value:
                    continue
                v = str(value).strip()
                if "copart.com/lot/" in v:
                    v = v.strip().strip('"').strip()
                    links_set.add(v)

    unique_links = sorted(links_set)
    print(f"üîó –ù–∞–π–¥–µ–Ω–æ —Å—Å—ã–ª–æ–∫: {len(unique_links)}")
    if unique_links[:5]:
        print("–ü—Ä–∏–º–µ—Ä—ã —Å—Å—ã–ª–æ–∫:")
        for l in unique_links[:5]:
            print("  ", l)
    return unique_links


# =======================
# –ú–∞–ø–ø–µ—Ä details -> VehicleModel (Factum style)
# =======================

def parse_odometer(odometer_str: str) -> tuple[int, Optional[str]]:
    """
    '101,779 mi (ACTUAL)' -> (101779, 'ACTUAL')
    """
    if not odometer_str:
        return 0, None
    digits = "".join(ch for ch in odometer_str if ch.isdigit())
    value = int(digits) if digits else 0

    brand = None
    m = re.search(r"\(([^()]+)\)", odometer_str)
    if m:
        brand = m.group(1).strip()
    return value, brand


def parse_year_from_title(title: str) -> Optional[int]:
    if not title:
        return None
    m = re.match(r"^\s*(\d{4})\b", title)
    if m:
        try:
            return int(m.group(1))
        except ValueError:
            return None
    return None


def split_title(title: str) -> tuple[Optional[int], Optional[str], Optional[str], Optional[str]]:
    """
    '2014 UTIL REEFER 53' - Refrigerated Van Trailer'
    -> year, make, model, body_type
    """
    if not title:
        return None, None, None, None
    parts = title.split(" - ", 1)
    left = parts[0].strip()
    body_type = parts[1].strip() if len(parts) > 1 else ""
    words = left.split()
    if not words:
        return None, None, None, body_type
    year: Optional[int] = None
    make: Optional[str] = None
    model: Optional[str] = None
    if re.fullmatch(r"\d{4}", words[0]):
        try:
            year = int(words[0])
        except ValueError:
            year = None
        if len(words) >= 2:
            make = words[1]
            model = " ".join(words[2:]) or None
    else:
        make = words[0]
        model = " ".join(words[1:]) or None
    return year, make, model, body_type


def parse_cylinders(cyl_str: str) -> Optional[int]:
    """
    '6' -> 6, '3.0L  6' -> 6, '' -> None
    """
    if not cyl_str:
        return None
    m = re.search(r"\d+", cyl_str)
    if not m:
        return None
    try:
        return int(m.group(0))
    except ValueError:
        return None


def build_image_sets(images: List[str]) -> tuple[List[str], List[str], Optional[str]]:
    """
    images (thumbnails) -> (link_img_small, link_img_hd, image_thumbnail)

    small  ‚Äî –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ thumbnail'—ã (_thb).
    hd     ‚Äî —Ç–æ–ª—å–∫–æ high-res –≤–∞—Ä–∏–∞–Ω—Ç—ã (_hrs) –¥–ª—è –∫–∞–∂–¥–æ–≥–æ thumbnail.
    """
    thumbs: List[str] = []
    hd: List[str] = []

    for url in images or []:
        url = (url or "").strip()
        if not url:
            continue

        # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π thumbnail
        thumbs.append(url)

        # –µ—Å–ª–∏ —ç—Ç–æ thumbnail –≤–∏–¥–∞ ..._thb.jpg ‚Äî —Å—Ç—Ä–æ–∏–º —Å—Å—ã–ª–∫—É –Ω–∞ HD
        if "_thb" in url:
            base = url.replace("_thb", "")
            if base.endswith((".jpg", ".jpeg", ".png")):
                base_no_ext, ext = os.path.splitext(base)
            else:
                base_no_ext, ext = base, ""

            # üî• –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ HRS (—Å–∞–º–æ–µ –ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ)
            hd.append(f"{base_no_ext}_hrs{ext}")

    # —É–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏ (–Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π)
    thumbs = list(dict.fromkeys(thumbs))
    hd = list(dict.fromkeys(hd))

    image_thumbnail = thumbs[0] if thumbs else None
    return thumbs, hd, image_thumbnail


async def mirror_copart_images_to_s3(
    lot_id: str,
    thumbs: List[str],
    client: Optional[httpx.AsyncClient] = None,
) -> tuple[List[str], List[str]]:
    """
    –ë–µ—Ä—ë–º thumbnail-URLs Copart, —Å—á–∏—Ç–∞–µ–º –∏–∑ –Ω–∏—Ö small + HD,
    –∫–∞—á–∞–µ–º –∏ –≥—Ä—É–∑–∏–º –≤ S3 –ü–ê–†–ê–õ–õ–ï–õ–¨–ù–û —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É.

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (s3_small_urls, s3_hd_urls).
    """
    small_urls, hd_urls, _ = build_image_sets(thumbs)

    sem = asyncio.Semaphore(IMAGE_CONCURRENCY)

    # –µ—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç –Ω–µ –ø–µ—Ä–µ–¥–∞–ª–∏ ‚Äî —Å–æ–∑–¥–∞—ë–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π
    own_client = client is None
    if own_client:
        client = httpx.AsyncClient(timeout=30)

    assert client is not None

    async def _process_one(idx: int, url: str, kind: str) -> Optional[str]:
        url = (url or "").strip()
        if not url:
            return None

        async with sem:
            try:
                resp = await client.get(url)
                resp.raise_for_status()
            except Exception as e:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å {kind}-–∫–∞—Ä—Ç–∏–Ω–∫—É {url}: {e}")
                return None

            ct = (
                resp.headers.get("content-type")
                or mimetypes.guess_type(url)[0]
                or "image/jpeg"
            )
            ext = (
                mimetypes.guess_extension(ct)
                or os.path.splitext(urlparse(url).path)[1]
                or ".jpg"
            )

            key = f"copart/{lot_id}/{kind}/{idx:03d}{ext}"
            fileobj = BytesIO(resp.content)

            try:
                await s3_service.upload_fileobj(
                    fileobj=fileobj,
                    key=key,
                    content_type=ct,
                    public_read=True,
                )
            except Exception as e:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å {kind}-–∫–∞—Ä—Ç–∏–Ω–∫—É –≤ S3 ({key}): {e}")
                return None

            public_url = s3_service.build_public_url(key)
            public_url = public_url.replace(
                "https://usc1.contabostorage.com/fadder",
                settings.CONTABO_S3_PUBLIC_URL,
            )
            print(public_url)
            return public_url

    try:
        small_tasks = [
            _process_one(idx, url, "small") for idx, url in enumerate(small_urls)
        ]
        hd_tasks = [
            _process_one(idx, url, "hd") for idx, url in enumerate(hd_urls)
        ]

        s3_small = [u for u in await asyncio.gather(*small_tasks) if u]
        s3_hd = [u for u in await asyncio.gather(*hd_tasks) if u]

        return s3_small, s3_hd
    finally:
        if own_client:
            await client.aclose()



def map_factum_to_model_from_details(item: Dict[str, Any]) -> Optional[Dict[str, Any]]:
    """
    –ú–∞–ø–ø–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö, –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –∏–∑ get_lot_details(), –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—É VehicleModel/VehicleModelOther.

    –ï—Å–ª–∏ –ª–æ—Ç –∑–∞–≤–µ–¥–æ–º–æ –Ω–µ–≤–∞–ª–∏–¥–µ–Ω (–Ω–µ—Ç lot_number, –Ω–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è year,
    VIN –Ω–µ 17 —Å–∏–º–≤–æ–ª–æ–≤ –∏ —Ç.–ø.) ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç None (—Ç–∞–∫–æ–π –ª–æ—Ç –º–æ–∂–Ω–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å).
    """

    # ---------- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ----------

    def s(x: Any) -> str:
        """–ì–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ –≤–µ—Ä–Ω—É—Ç—å —Å—Ç—Ä–æ–∫—É (–¥–ª—è –ø–æ–ª–µ–π, –≥–¥–µ Pydantic —Ö–æ—á–µ—Ç str, –∞ –Ω–µ None)."""
        if x is None:
            return ""
        x = str(x).strip()
        return x

    def parse_year_from_title(title: str) -> Optional[int]:
        """–ò—â–µ–º –≥–æ–¥ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ, –Ω–∞–ø—Ä–∏–º–µ—Ä '2014 UTIL REEFER 53' - ...'."""
        if not title:
            return None
        m = re.search(r"\b(19\d{2}|20\d{2})\b", title)
        if not m:
            return None
        try:
            return int(m.group(1))
        except ValueError:
            return None

    def parse_current_bid(bid_raw: str) -> int:
        """
        '$4,000.00' -> 4000
        '‚Ç¨ 1 500'   -> 1500
        """
        bid_raw = bid_raw or ""
        digits = re.sub(r"[^\d]", "", bid_raw)
        return int(digits) if digits else 0


    def parse_make_model_body_type(title: str) -> tuple[str, str, str]:
        """
        –ó–∞–≥–æ–ª–æ–≤–æ–∫ –≤–∏–¥–∞:
          '2014 UTIL REEFER 53' - Refrigerated Van Trailer'
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (make, model, body_type).
        """
        title = title or ""
        body_type = ""
        left = title
        if "-" in title:
            left, right = title.split("-", 1)
            body_type = right.strip()

        left = left.strip()
        parts = left.split()

        year_str = None
        if parts and re.fullmatch(r"(19\d{2}|20\d{2})", parts[0]):
            year_str = parts[0]
            parts = parts[1:]

        make = parts[0] if parts else ""
        model = " ".join(parts[1:]) if len(parts) > 1 else ""

        # –ü—Ä–∏–≤–æ–¥–∏–º –∫—Ä–∞—Å–∏–≤–æ: –ø–µ—Ä–≤–∞—è –±—É–∫–≤–∞ –±–æ–ª—å—à–∞—è, –æ—Å—Ç–∞–ª—å–Ω—ã–µ –º–∞–ª–µ–Ω—å–∫–∏–µ
        make = make.title()
        model = model.title()
        body_type = body_type.title()

        return make, model, body_type

    def parse_odometer(odo_raw: str) -> tuple[int, str]:
        """
        '101,779 mi (ACTUAL)' ‚Üí (101779, 'ACTUAL')
        '0 mi (NOT ACTUAL)'  ‚Üí (0, 'NOT ACTUAL')
        """
        odo_raw = odo_raw or ""
        # —á–∏—Å–ª–æ
        m_num = re.search(r"([\d,]+)", odo_raw)
        if m_num:
            num = int(m_num.group(1).replace(",", ""))
        else:
            num = 0

        # –±—Ä–µ–Ω–¥ –æ–¥–æ–º–µ—Ç—Ä–∞ (–≤ —Å–∫–æ–±–∫–∞—Ö)
        m_brand = re.search(r"\(([^)]+)\)", odo_raw)
        brand = m_brand.group(1).strip() if m_brand else ""

        return num, brand

    def derive_hd_images(thumbnails: List[str]) -> List[str]:
        """
        –ò–∑ thumbnail'–æ–≤ –≤–∏–¥–∞ ..._thb.jpg –¥–µ–ª–∞–µ–º —Å–ø–∏—Å–æ–∫ HD-—Å—Å—ã–ª–æ–∫:
        ..._ful.jpg –∏ ..._hrs.jpg
        """
        hd: List[str] = []
        for url in thumbnails:
            url = url.strip()
            if not url:
                continue
            if "_thb" in url:
                base = url.replace("_thb.jpg", "")
                hd.append(base + "_ful.jpg")
                hd.append(base + "_hrs.jpg")
            else:
                # –µ—Å–ª–∏ –≤–¥—Ä—É–≥ —É–∂–µ HD ‚Äî –ø—Ä–æ—Å—Ç–æ –¥–æ–±–∞–≤–∏–º –∫–∞–∫ –µ—Å—Ç—å
                hd.append(url)
        # –£–Ω–∏–∫–∞–ª–∏–∑–∏—Ä—É–µ–º
        return list(dict.fromkeys(hd))

    def calc_auction_datetime(time_left_str: str) -> Optional[str]:
        """
        –ü—Ä–µ–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä–æ–∫—É –≤–∏–¥–∞ '0D 4H 41min' –≤ ISO datetime (UTC), –Ω–∞–ø—Ä–∏–º–µ—Ä:
        '2025-11-20T19:41:00+00:00'
        """
        time_left_str = (time_left_str or "").strip()
        if not time_left_str:
            return None

        m = re.search(r"(\d+)D\s+(\d+)H\s+(\d+)min", time_left_str)
        if not m:
            return None

        days = int(m.group(1))
        hours = int(m.group(2))
        minutes = int(m.group(3))

        now = datetime.now(timezone.utc)
        dt = now + timedelta(days=days, hours=hours, minutes=minutes)
        return dt.isoformat()

    # ---------- –†–∞–∑–±–æ—Ä –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö ----------

    title = s(item.get("title"))
    lot_number_raw = item.get("lot_number") or item.get("lot_id") or ""

    lot_number_str = s(lot_number_raw)
    if not lot_number_str.isdigit():
        # –±–µ–∑ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ lot_id –≤ –±–∞–∑—É –Ω–µ —à–ª—ë–º
        return None
    lot_id = int(lot_number_str)

    vin = s(item.get("vin")).upper()
    # –∂—ë—Å—Ç–∫–æ–µ –ø—Ä–∞–≤–∏–ª–æ –±—ç–∫–µ–Ω–¥–∞: VIN –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–æ–≤–Ω–æ 17 —Å–∏–º–≤–æ–ª–æ–≤
    if len(vin) != 17:
        return None

    year = parse_year_from_title(title)
    if year is None:
        # –±—ç–∫–µ–Ω–¥ —Ä—É–≥–∞–ª—Å—è, –µ—Å–ª–∏ year –±—ã–ª None, –ø–æ—ç—Ç–æ–º—É –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–∞–∫–∏–µ –ª–æ—Ç—ã
        return None

    # odometer + odobrand
    odometer_raw = s(item.get("odometer"))
    odometer_val, odobrand = parse_odometer(odometer_raw)

    # Sale state/location
    sale_location = s(item.get("sale_location"))
    sale_state = s(item.get("sale_state"))
    if not sale_state and " - " in sale_location:
        # 'CT - HARTFORD SPRINGFIELD' ‚Üí 'CT'
        sale_state = sale_location.split(" - ", 1)[0].strip()

    # Time left ‚Üí auction_date (–ø–æ–ª–Ω—ã–π datetime)
    auction_date_iso = calc_auction_datetime(item.get("time_left"))


    current_bid_raw = s(item.get("current_bid"))
    current_bid_val = parse_current_bid(current_bid_raw)
    estimated_raw = s(item.get("estimated_retail_value"))
    estimated_val = parse_current_bid(estimated_raw)
    # make/model/body_type –∏–∑ title
    make, model, body_type_from_title = parse_make_model_body_type(title)
    body_type = None
    if not body_type_from_title:
        body_type = s(item.get("body_type_nhtsa"))
    else:
        body_type = body_type_from_title
    # –¶–∏–ª–∏–Ω–¥—Ä—ã ‚Üí int
    cylinders_raw = s(item.get("cylinders"))
    if cylinders_raw.isdigit():
        cylinders = int(cylinders_raw)
    else:
        cylinders = 0  # —á—Ç–æ–±—ã –Ω–µ –≤—ã–∑—ã–≤–∞—Ç—å int_parsing –Ω–∞ '' –∏–ª–∏ None

    # –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ–ª—è –∫–∞–∫ —Å—Ç—Ä–æ–∫–∏
    primary_damage = s(item.get("primary_damage"))
    color = s(item.get("color"))
    engine_type = s(item.get("engine_type"))
    transmission = s(item.get("transmission"))
    drive = s(item.get("drive"))
    vehicle_type = s(item.get("vehicle_type"))
    fuel = s(item.get("fuel"))
    keys = s(item.get("keys"))
    title_code = s(item.get("title_code"))

    # –∫–∞—Ä—Ç–∏–Ω–∫–∏
    thumbs: List[str] = item.get("images_small") or item.get("images") or []
    thumbs = [t for t in thumbs if t]

    hd_list: List[str] = item.get("images_hd") or []
    hd_list = [u for u in hd_list if u]

    link_img_small = thumbs
    link_img_hd = hd_list or thumbs  # –µ—Å–ª–∏ HD –Ω–µ—Ç, –¥—É–±–ª–∏—Ä—É–µ–º small
    image_thumbnail = thumbs[0] if thumbs else (hd_list[0] if hd_list else None)

    now_iso = datetime.now(timezone.utc).isoformat()

    # ---------- –§–∏–Ω–∞–ª—å–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –ø–æ–¥ VehicleModel / VehicleModelOther ----------

    return {
        "lot_id": lot_id,
        "base_site": "copart",          # —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ
        "odometer": odometer_val,
        "price": 0,
        "reserve_price": 0,
        "bid": 0,
        "current_bid": current_bid_val,
        "auction_date": auction_date_iso,  # ‚úÖ –ø–æ–ª–Ω–æ–µ datetime ISO –∏–∑ Time left
        "cost_repair": estimated_val or 0,
        "year": year,
        "cylinders": cylinders,
        "state": sale_state,               # —Å—Ç—Ä–æ–∫–∞, –Ω–µ None
        "location": sale_location,         # —Å—Ç—Ä–æ–∫–∞, –Ω–µ None

        "vehicle_type": vehicle_type,
        "make": make,
        "model": model,
        "damage_pr": primary_damage,
        "damage_sec": "",
        "keys": keys,
        "odobrand": odobrand,
        "fuel": fuel,
        "drive": drive,
        "transmission": transmission,
        "color": color,
        "status": "",
        "auction_status": "Not Sold",
        "body_type": body_type,
        "series": "",
        "title": title,

        "vin": vin,
        "engine": engine_type,
        "engine_size": None,
        "location_old": "",
        "country": "USA",

        "document": title_code,
        "document_old": "",
        "seller": "",

        "image_thubnail": image_thumbnail,
        "is_buynow": False,
        "link_img_hd": link_img_hd,
        "link_img_small": link_img_small,
        "link": s(item.get("lot_link")),
        "seller_type": "",

        "risk_index": None,
        "created_at": now_iso,
        "updated_at": now_iso,
        "is_historical": False,
    }

# =======================
# –û—Ç–ø—Ä–∞–≤–∫–∞ –±–∞—Ç—á–µ–π –≤ API
# =======================

def send_batchs(models: List[Dict[str, Any]], chunk_size: int = MAX_BATCH_SIZE):
    if not models:
        print("‚ÑπÔ∏è –ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π, –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –Ω–µ—á–µ–≥–æ.")
        return

    headers = {
        "Authorization": LOCAL_AUTH,
        "content-type": "application/json",
    }

    total = len(models)
    print(f"üöö –û—Ç–ø—Ä–∞–≤–ª—è—é {total} –ª–æ—Ç–æ–≤ –≤ {LOCAL_BATCH_URL} –±–∞—Ç—á–∞–º–∏ –ø–æ {chunk_size} ...")

    # –û–¥–∏–Ω httpx.Client –Ω–∞ –≤—Å–µ –±–∞—Ç—á–∏ ‚Üí —Ä–µ—é–∑ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è, –±—ã—Å—Ç—Ä–µ–µ –∏ –∞–∫–∫—É—Ä–∞—Ç–Ω–µ–µ
    with httpx.Client(timeout=30) as client:
        for i in range(0, total, chunk_size):
            chunk = models[i: i + chunk_size]
            print(f"  ‚Üí –±–∞—Ç—á {i+1}-{i+len(chunk)} (–∏–∑ {total})")

            try:
                resp = client.post(LOCAL_BATCH_URL, json=chunk, headers=headers)
            except httpx.RequestError as e:
                print(f"    ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –±–∞—Ç—á–∞: {e}")
                continue

            print("    STATUS:", resp.status_code)
            try:
                print("    RESPONSE JSON:", resp.json())
            except Exception:
                print("    RESPONSE TEXT:", resp.text[:1000])


def calc_auction_datetime(time_left_str: str) -> str | None:
    """
    –ü—Ä–µ–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä–æ–∫—É –≤–∏–¥–∞:
       '0D 4H 41min'
       '4D 3H 5min'
    –≤ UTC ISO –¥–∞—Ç—É:
       '2025-11-20T19:41:00Z'
    """

    if not time_left_str:
        return None

    # –ò—â–µ–º —Ñ–æ—Ä–º–∞—Ç–∞ 4D 3H 5min
    m = re.search(r"(\d+)D\s+(\d+)H\s+(\d+)min", time_left_str)
    if not m:
        return None

    days = int(m.group(1))
    hours = int(m.group(2))
    minutes = int(m.group(3))

    # –¢–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è –≤ UTC
    now = datetime.now(timezone.utc)

    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª
    dt = now + timedelta(days=days, hours=hours, minutes=minutes)

    return dt.isoformat()


# =======================
# –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞
# =======================

async def fetch_details_for_links(bot: CopartBot, links: List[str]) -> List[Dict[str, Any]]:
    results: List[Dict[str, Any]] = []
    total = len(links)

    async with httpx.AsyncClient(timeout=30) as client:
        for idx, url in enumerate(links, start=1):
            lot_id_from_url = url.split("/lot/")[-1].split("/")[0]
            print(f"[{idx}/{total}] –¢—è–Ω—É –¥–µ—Ç–∞–ª–∏ –ª–æ—Ç–∞ {lot_id_from_url}‚Ä¶")
            try:
                details = await bot.get_lot_details(url)

                # --------- NHTSA: Body Class ---------
                vin_raw = (details.get("vin") or "").strip().upper()
                if len(vin_raw) == 17:
                    body_class = await fetch_body_class_from_nhtsa(vin_raw, client)
                    if body_class:
                        # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–º –∫–ª—é—á–æ–º, —á—Ç–æ–±—ã –±—ã–ª–æ –≤–∏–¥–Ω–æ –∏—Å—Ç–æ—á–Ω–∏–∫
                        details["body_type_nhtsa"] = body_class
                        print(f"  üß¨ NHTSA Body Class –¥–ª—è VIN {vin_raw}: {body_class}")
                # -------------------------------------

                # ---------- DEBUG: —á—Ç–æ –ø—Ä–∏—à–ª–æ —Å Copart ----------
                copart_imgs: List[str] = details.get("images") or []
                print(f"  üñºÔ∏è Copart thumbnails ({len(copart_imgs)} —à—Ç.):")
                for img_url in copart_imgs:
                    print(f"      {img_url}")
                # ------------------------------------------------

                # –æ–ø—Ä–µ–¥–µ–ª—è–µ–º lot_id –¥–ª—è –∫–ª—é—á–µ–π –≤ S3
                lot_number = details.get("lot_number") or lot_id_from_url
                lot_id_str = str(lot_number)

                # –∏—Å—Ö–æ–¥–Ω—ã–µ thumbnail'—ã —Å Copart
                thumbs: List[str] = copart_imgs

                # –∑–∞–ª–∏–≤–∞–µ–º –≤ S3 ‚Üí –ø–æ–ª—É—á–∞–µ–º S3 small / hd (—É–∂–µ async + –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ)
                s3_small, s3_hd = await mirror_copart_images_to_s3(
                    lot_id_str,
                    thumbs,
                    client=client,
                )

                # ---------- DEBUG: —á—Ç–æ –ø–æ–ª—É—á–∏–ª–æ—Å—å –≤ S3 ----------
                print(f"  ‚òÅÔ∏è S3 small ({len(s3_small)} —à—Ç.):")
                for img_url in s3_small:
                    print(f"      {img_url}")

                print(f"  ‚òÅÔ∏è S3 HD ({len(s3_hd)} —à—Ç.):")
                for img_url in s3_hd:
                    print(f"      {img_url}")
                # ------------------------------------------------

                # —Å–æ—Ö—Ä–∞–Ω—è–µ–º S3-—Å—Å—ã–ª–∫–∏ –≤ –¥–µ—Ç–∞–ª—è—Ö
                details["images_small"] = s3_small
                details["images_hd"] = s3_hd
                details["images"] = s3_small  # –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏

                results.append(details)
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–∑–±–æ—Ä–µ –ª–æ—Ç–∞ {lot_id_from_url}: {e}")

    return results


async def main():
    print(f"‚öôÔ∏è START_LINK_INDEX = {START_LINK_INDEX}")

    if not COPART_USER or not COPART_PASS:
        print("‚õî –£–∫–∞–∂–∏ COPART_USER –∏ COPART_PASS –≤ .env")
        return

    store = SessionStore("sessions.db")
    await store.init()

    bot = CopartBot(username=COPART_USER, password=COPART_PASS, headless=HEADLESS)
    await bot.start(storage_state=await store.get_storage_state(COPART_USER))

    try:
        if not await bot.ensure_session(store):
            print("‚õî –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å")
            return
        print("‚úÖ –°–µ—Å—Å–∏—è –≤–∞–ª–∏–¥–Ω–∞")

        # 1) –°–ö–ê–ß–ò–í–ê–ù–ò–ï CSV –ß–ï–†–ï–ó EXPORT
        csv_path = await bot.export_csv_once()
        if not csv_path:
            print("‚õî –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø—É—Ç—å –∫ CSV")
            return

        # 2) –í–´–¢–ê–°–ö–ò–í–ê–ï–ú –°–°–´–õ–ö–ò –ò–ó CSV
        links = extract_links_from_csv(csv_path)
        if not links:
            print("‚õî –í CSV –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–π —Å—Å—ã–ª–∫–∏ –Ω–∞ –ª–æ—Ç—ã")
            return

        original_total_links = len(links)
        print(f"\nüî¢ –í—Å–µ–≥–æ —Å—Å—ã–ª–æ–∫ –Ω–∞ –ª–æ—Ç—ã: {original_total_links}")

        if original_total_links:
            print(f"   –ü–µ—Ä–≤—ã–π URL –¥–æ –æ–±—Ä–µ–∑–∫–∏: {links[0]}")

        # üî¢ –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –Ω–∞—á–∞—Ç—å –Ω–µ —Å –ø–µ—Ä–≤–æ–π, –∞, –Ω–∞–ø—Ä–∏–º–µ—Ä, —Å 540-–π
        global_start_index = 0  # –≥–ª–æ–±–∞–ª—å–Ω—ã–π —Å–¥–≤–∏–≥ –ø–æ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º—É —Å–ø–∏—Å–∫—É

        if START_LINK_INDEX > 0:
            if START_LINK_INDEX >= original_total_links:
                print(
                    f"‚ö†Ô∏è START_LINK_INDEX={START_LINK_INDEX} –±–æ–ª—å—à–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—Å—ã–ª–æ–∫ "
                    f"({original_total_links}), –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –Ω–µ—á–µ–≥–æ."
                )
                return

            global_start_index = START_LINK_INDEX

            print(
                f"‚è© –ü—Ä–æ–ø—É—Å–∫–∞—é –ø–µ—Ä–≤—ã–µ {START_LINK_INDEX} —Å—Å—ã–ª–æ–∫, "
                f"–Ω–∞—á–∏–Ω–∞—é —Å {START_LINK_INDEX + 1}-–π (1-based –Ω—É–º–µ—Ä–∞—Ü–∏—è –≤ –∏—Å—Ö–æ–¥–Ω–æ–º —Å–ø–∏—Å–∫–µ)."
            )
            # –û–±—Ä–µ–∑–∞–µ–º —Å–ø–∏—Å–æ–∫ —Å—Å—ã–ª–æ–∫ ‚Äî –¥–∞–ª—å—à–µ —Ä–∞–±–æ—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ —Å ¬´—Ö–≤–æ—Å—Ç–æ–º¬ª
            links = links[START_LINK_INDEX:]
            print(f"   –ü–µ—Ä–≤—ã–π URL –ü–û–°–õ–ï –æ–±—Ä–µ–∑–∫–∏: {links[0]}")

        total_links = len(links)
        print(f"üî¢ –°—Å—ã–ª–æ–∫ –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ –ø–æ—Å–ª–µ –æ–±—Ä–µ–∑–∫–∏: {total_links}")

        BATCH_SIZE = 5
        total_sent = 0
        total_skipped = 0
        first_example_printed = False

        # 3) –ò–î–Å–ú –ü–û –°–°–´–õ–ö–ê–ú –ë–ê–¢–ß–ê–ú–ò –ü–û 20
        for start in range(0, total_links, BATCH_SIZE):
            batch_links = links[start:start + BATCH_SIZE]

            # –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞ (0-based ‚Üí 1-based)
            global_index_start = global_start_index + start + 1
            global_index_end = global_start_index + start + len(batch_links)

            print(
                f"\nüöÄ –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ —Å—Å—ã–ª–æ–∫ {global_index_start}‚Äì{global_index_end} "
                f"–∏–∑ {original_total_links}"
            )

            # 3.1) –¢–Ø–ù–ï–ú –î–ï–¢–ê–õ–ò –ü–û –ë–ê–¢–ß–£ –°–°–´–õ–û–ö
            # (–≤–Ω—É—Ç—Ä–∏ —É–∂–µ –¥–µ—Ä–≥–∞–µ—Ç—Å—è NHTSA + –∫–∞—Ä—Ç–∏–Ω–∫–∏ ‚Üí S3)
            details_list = await fetch_details_for_links(bot, batch_links)
            print(f"  ‚úÖ –í —ç—Ç–æ–º –±–∞—Ç—á–µ —Ä–∞–∑–æ–±—Ä–∞–Ω–æ –ª–æ—Ç–æ–≤: {len(details_list)}")

            # 3.2) –ú–ê–ü–ü–ò–ú –í –§–û–†–ú–ê–¢ FACTUM / VehicleModel
            mapped_batch: List[Dict[str, Any]] = []
            skipped_batch = 0
            for d in details_list:
                m = map_factum_to_model_from_details(d)
                if m is None:
                    skipped_batch += 1
                    continue
                mapped_batch.append(m)

            total_sent += len(mapped_batch)
            total_skipped += skipped_batch

            print(
                f"  üì¶ –í —ç—Ç–æ–º –±–∞—Ç—á–µ –≥–æ—Ç–æ–≤–æ –º–æ–¥–µ–ª–µ–π –∫ –æ—Ç–ø—Ä–∞–≤–∫–µ: {len(mapped_batch)}, "
                f"–ø—Ä–æ–ø—É—â–µ–Ω–æ (–Ω–µ–≤–∞–ª–∏–¥–Ω—ã–µ): {skipped_batch}"
            )

            # 3.3) –î–ª—è –ø–µ—Ä–≤–æ–≥–æ –≤–∞–ª–∏–¥–Ω–æ–≥–æ –±–∞—Ç—á–∞ –ø–æ–∫–∞–∂–µ–º –ø—Ä–∏–º–µ—Ä
            if mapped_batch and not first_example_printed:
                print("\n–ü—Ä–∏–º–µ—Ä mapped[0]:")
                for k, v in mapped_batch[0].items():
                    print(f"  {k}: {v}")
                first_example_printed = True

            # 3.4) –û–¢–ü–†–ê–í–ö–ê –≠–¢–û–ì–û –ë–ê–¢–ß–ê –í API
            if mapped_batch:
                send_batchs(mapped_batch, chunk_size=BATCH_SIZE)
            else:
                print("  ‚ö†Ô∏è –í —ç—Ç–æ–º –±–∞—Ç—á–µ –Ω–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏.")

        print(
            f"\n‚úÖ –ì–æ—Ç–æ–≤–æ. –í—Å–µ–≥–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –º–æ–¥–µ–ª–µ–π: {total_sent}, "
            f"–ø—Ä–æ–ø—É—â–µ–Ω–æ (–Ω–µ–≤–∞–ª–∏–¥–Ω—ã–µ): {total_skipped}"
        )

    finally:
        await bot.close()


if __name__ == "__main__":
    asyncio.run(main())
